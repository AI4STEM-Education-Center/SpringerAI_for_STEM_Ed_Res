Kıyak’s prompt and Zuckerman et al.'s prompt for the Case-based MCQ Generator
Prompt:
The first file includes Kıyak’s prompt and its reference:
“Here is Kıyak’s prompt, it necessitates user to provide a topic or learning objective and difficulty level: [Reference: Kıyak, Y. S. (2023). A ChatGPT Prompt for Writing Case-Based Multiple-Choice Questions. Revista Española de Educación Médica, 4(3), 98-103]
You are developing a question bank for medical exams focusing on the topic of [PLEASE INSERT A TOPIC]. Please generate a high-quality single best answer multiple-choice question. Follow the principles of constructing multiple-choice items in medical education. Generate the questions using the following framework:
Case (write as a single narrative paragraph without providing each part separately):
    Patient details (gender/age)
    Presenting complaint
    Relevant clinical history
    Physical examination findings
    Diagnostic test results (optional)
Question stem: [Insert relevant information from the above sections without compromising the answer]
Acceptable question style: Ask for the BEST answer, NOT one that is TRUE/FALSE.
Answer options:
    [Insert plausible answer option]
    [Insert plausible answer option]
    [Insert plausible answer option]
    [Insert plausible answer option]
    [Insert plausible answer option]
Explanation:
• Identify and explain the correct answer.
• Explain why this is the most appropriate answer based on evidence-based guidelines or expert consensus.
• Briefly explain why the other answer options are less correct or incorrect.
Difficulty level: [PLEASE INSERT A DIFFICULTY LEVEL (E.G. EASY, DIFFICULT]”
The prompt above has been copied from the article titled 'A ChatGPT Prompt for Writing Case-Based Multiple-Choice Questions' authored by Yavuz Selim Kıyak and published in Revista Española de Educación Médica in 2023, available at https://doi.org/10.6018/edumed.587451, under a Creative Commons Attribution-NonCommercial-NoDerivs 4.0 International License.

The second file includes Zuckerman’s prompt and its reference:
“Here is Zuckerman et al.’s prompt, it necessitates user to provide an item-specific test point (learning objective or disease state or physical exam finding): [Reference: Zuckerman, M., Flood, R., Tan, R. J., Kelp, N., Ecker, D. J., Menke, J., & Lockspeiser, T. (2023). ChatGPT for assessment writing. Medical Teacher, 45(11), 1224-1227]
Write a multiple-choice question in NBME format with 4 sentence clinical vignette, vital signs, and exam findings. Avoid pseudovignettes. [INSERT Item-Specific Test Point: learning objective or disease state or physical exam finding]”

